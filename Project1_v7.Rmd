---
title: "Modeling Assignment 1, Hendrik's benchmark"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup

```{r}
# add your libraries
library(tidyverse)
library(caret)
library(rpart)
library(randomForest)
wine = read_rds("https://raw.githubusercontent.com/bobbyjy/MyData/main/pinot.rds")

```


## Feature Engineering

```{r}
# create some cool features. Make sure you add comments so I know what you are trying to accomplish!

#the function!
wine_words <- function(df, j = 1000, stem=F){ 
  library(tidytext)
  library(SnowballC)
  data(stop_words)

  words <- df %>%
    unnest_tokens(word, description) %>%
    anti_join(stop_words) %>% # get rid of stop words
    filter(!(word %in% c("wine","pinot","vineyard")))
  
  if(stem){
    words <- words %>% 
      mutate(word = wordStem(word))
  }
  
  words <- words %>% 
    count(id, word) %>% 
    group_by(id) %>% 
    mutate(exists = (n>0)) %>% 
    ungroup %>% 
    group_by(word) %>% 
    mutate(total = sum(n)) %>% 
    filter(total > j) %>% 
    pivot_wider(id_cols = id, names_from = word, values_from = exists, values_fill = list(exists=0)) %>% 
    right_join(dplyr::select(df,id,province)) %>% 
    dplyr::select(-id) %>% 
    mutate(across(-province, ~replace_na(.x, F)))
}


```


## Specification

```{r}
set.seed(500)
# specify the model to be used (i.e. KNN or Naive Bayes) and the tuning parameters used
wine = read_rds("https://raw.githubusercontent.com/bobbyjy/MyData/main/pinot.rds")
#training the fit on the adjusted data set, played with some weightings but this didn't help a lot
wine <- wine %>% 
  mutate(points = scale(points, center = T, scale = T)) %>%
  mutate(price = scale(log(price), center = T, scale = T)) 

wino <- wine_words(wine, j=5, stem = T)
wino$price <- wine$price
wino$points <- wine$points
wine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)
train <- wino[ wine_index, ]
###the model can't look at the test set...###
test <- wino[-wine_index, ]


####conduct data duplication on only the train set####
sample_size = 400

burg_sample <- train %>%
  filter(province=='Burgundy') %>% 
    sample_n(sample_size, replace = T)

cali_sample <- train %>%
  filter(province=='California') %>% 
    sample_n(800, replace = T) #800 got .84

casa_sample <- train %>%
  filter(province=='Casablanca_Valley') %>% 
    sample_n(sample_size, replace = T)

marl_sample <- train %>%
  filter(province=='Marlborough') %>% 
    sample_n(sample_size, replace = T)

york_sample <- train %>%
  filter(province=='New_York') %>% 
    sample_n(sample_size, replace = T)

oreg_sample <- train %>%
  filter(province=='Oregon') %>% 
    sample_n(800, replace = T) #800 got .84

train <- rbind(burg_sample,cali_sample,casa_sample,marl_sample,york_sample,oreg_sample)

#train

weight_train <- train %>% 
  mutate(weights=case_when(
    province=="Burgundy" ~ 1,
    province=="California" ~ 1,
    province=="Casablanca_Valley" ~ 1,
    province=="Marlborough" ~ 1,
    province=="New_York" ~ 1,
    province=="Oregon" ~ 1))


####################################
##this takes like 3 hours to run####
####################################

ctrl <- trainControl(method = "repeatedcv", number = 5, repeats = 1)

fit <- train(province ~ .,
             data = train,
             method = "rf",
             trControl = ctrl,
             ntree=100,
             weights = weight_train$weights
             )

# fit <- train(province ~ .,
#              data = train,
#              trControl = ctrl,
#              method = "treebag"
#              
#              )
# 
# #fit83
# #longFit
 pred <- predict(fit, newdata=test)
 confusionMatrix(factor(pred),factor(test$province))

```

```{r}
#reading the original datsetback in to run the fit
set.seed(500)
wine = read_rds("https://raw.githubusercontent.com/bobbyjy/MyData/main/pinot.rds")
wino <- wine_words(wine, j=25, stem = T)
wino$price <- wine$price
wino$points <- wine$points
wine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)
#train <- wino[ wine_index, ]
test <- wino[-wine_index, ]

#running the confusion matrix on the original wine data test group
pred <- predict(fit, newdata=test)
confusionMatrix(factor(pred),factor(test$province))
```


## Best model

```{r}
# Here are a few lines to inspect your best model. Add some comments about optimal hyperparameters.
print(fit)
print(fit$bestTune)
```


## Re-fit and evaluation

```{r}
# the "method" below should match the one you chose above. 

set.seed(1504) # I will choose a different seed for evaluation

wine_index <- createDataPartition(wino$province, p = 0.80, list = FALSE)
train <- wino[ wine_index, ]
test <- wino[-wine_index, ]

# example spec for knn
fit_final <- train(province ~ .,
             data = train, 
             method = "rpart",
             tuneGrid=fit$bestTune) 
# The last line means we will fit a model using the best tune parameters your CV found above.

confusionMatrix(predict(fit_final, test),factor(test$province))
```

